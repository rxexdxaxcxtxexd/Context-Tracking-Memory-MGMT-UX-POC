# CSG-CONTEXT.md
# Cornerstone Solutions Group - Permanent Business Context

**Last Updated:** 2026-01-15
**Owner:** Luke Layden, Solution Delivery Manager

---

## 1. BUSINESS MODEL & GOALS

### What CSG Does

**Cornerstone Solutions Group (CSG)** is a mid-size software consulting and development firm (20-50 people) that provides comprehensive technology services to clients across multiple industries.

**Service Offerings:**
- **Custom Software Development** - Build new applications from scratch tailored to client needs
- **Legacy Modernization** - Update and migrate existing systems to modern platforms
- **Staff Augmentation** - Provide skilled developers to augment client teams
- **Consulting & Advisory** - Strategic guidance and technical consulting

**Industry Focus:**
- **Transportation & Logistics** (Primary) - Supply chain, fleet management, logistics (e.g., BargeOps)
- **Healthcare** - Medical, pharmaceutical, health tech solutions
- **Generalist Approach** - Also work across other industries as opportunities arise

**Typical Project Profile:**
- Mix of greenfield development, modernization, and ongoing support engagements
- Range from multi-month fixed-scope projects to ongoing T&M partnerships
- Team sizes vary from solo augmentation to full delivery teams

**Work Model:**
- Mostly in-office based with some flexibility
- Collaborative, team-oriented environment
- Strong emphasis on delivery excellence

### Revenue Model

**Pricing Approach:** Mixed model depending on project type
- **Time & Materials (T&M)** - For ongoing engagements, staff augmentation, exploratory work
- **Fixed-Price Projects** - For well-defined scope, clear deliverables
- **Retainer/Managed Services** - For long-term support and maintenance
- Flexibility to use the model that best fits client needs and risk profile

**Typical Engagement Types:**
1. **Greenfield Development** - Build new systems from requirements through deployment
2. **Modernization Projects** - Upgrade legacy systems, migrate platforms, refactor codebases
3. **Ongoing Support** - Maintain and enhance existing applications over time
4. **Team Augmentation** - Place developers on client teams for extended periods

### 2026 Strategic Goals

**Top 3 Priorities:**

1. **Revenue Growth** - Hit revenue targets, win new clients, expand existing accounts
2. **Operational Excellence** - Improve delivery efficiency, quality, and processes
3. **New Service Offerings** - Launch innovative capabilities like AI tooling portfolio

**Growth Targets:**
- Expand revenue through combination of new clients and deeper engagement with existing clients
- Maintain or improve margins through operational improvements and efficiency gains
- Position CSG as thought leaders in AI-driven delivery transformation

### Competitive Positioning

**What Makes CSG Different:**

1. **Long-Term Partnerships** - CSG becomes a trusted advisor and extension of client teams
   - Not just project vendors, but strategic partners who understand client business deeply
   - High client retention, multi-year relationships

2. **Agility & Speed** - Faster delivery, more responsive than larger competitors
   - Can pivot quickly to changing requirements
   - Less bureaucracy, faster decision-making
   - Proactive problem-solving

3. **Deep Industry Expertise** - Specialized knowledge in transportation/logistics and healthcare
   - Understand domain-specific challenges and regulations
   - Bring best practices from similar projects

**Market Position:** Premium-quality boutique firm competing on expertise and relationships rather than price

### Success Metrics

**What Defines Success for CSG:**

1. **Client Satisfaction** - High CSAT scores, repeat business, long-term retention
2. **Revenue & Profitability** - Hit growth targets while maintaining healthy margins
3. **Team Growth & Retention** - Attract and keep top talent, low turnover
4. **Delivery Quality** - On-time, on-budget delivery with minimal defects
5. **Innovation Leadership** - Recognized as innovators in AI-driven software delivery

---

## 2. CURRENT STATE (Q1 2026)

### Active Projects

| Project | Client | Status | Team Size | Luke's Role |
|---------|--------|--------|-----------|-------------|
| BargeOps Admin Web App | BargeOps | Active | TBD | SDM + AI Tools |

### Team Structure
[To be filled: Delivery teams, roles, reporting structure, collaboration patterns]

### Technology Stack
[To be filled: Common technologies, cloud platforms, tools, frameworks]

---

## 3. AI TOOLING PORTFOLIO PROGRAM

### Vision
Transform CSG delivery through curated portfolio of AI-driven tools

### 2026 OKRs

**O1: Build Compounding AI Tooling Portfolio**
- KR1: 10 production tools shipped
- KR2: 5 tools reused across 2+ teams
- KR3: 6 shared components/patterns created

**O2: Accelerate Delivery Across SDLC**
- KR1: 20 workflow interviews completed
- KR2: 30% faster execution (measured)
- KR3: 40% project adoption rate

**O3: Increase Quality**
- KR1: 75% tool acceptance rate
- KR2: CSAT ≥ 4.3/5
- KR3: 40% fewer revision cycles

**O4: Deploy Anti-Fragile AI Governance**
- KR1: 100% compliance (data security, IP, bias)
- KR2: 0 high-severity incidents
- KR3: Guardrails in every AI workflow

### Q1 2026 Deliverables
- [ ] Portfolio catalog structure + intake rubric
- [ ] CSG AI Standards checklist v1.0
- [ ] First 2 pilot tools in production
- [ ] 5 workflow interviews completed

---

## 4. TOOL PORTFOLIO CATALOG

### Shipped Tools

#### 1. CSG Sprint Reporter ✅ (Shipped Q4 2025)
- **Purpose:** Auto-generate sprint reports from Jira + Fathom meeting recordings
- **Status:** Production, actively used by BargeOps team
- **Reusability:** High (works for any CSG project with Jira + Fathom)
- **Impact:** 2-3 hours saved per sprint, better visibility into team progress
- **Technology:** Python, Jira API, Fathom API
- **Location:** `C:\Users\layden\scripts\csg-sprint-reporter.py`
- **Documentation:** `C:\Users\layden\scripts\CSG-SPRINT-REPORTER-README.md`
- **Next Steps:**
  - Document as case study for presentation
  - Share with other CSG teams
  - Measure adoption metrics

### In Progress

[Tools being built this quarter - to be added as development starts]

### Backlog (Prioritized)

**Q1-Q2 Focus:**
1. **UI Test Generation** - Generate Playwright/Cypress tests from wireframes and user flows
2. **Requirements Gathering Assistant** - Transform stakeholder interviews into structured user stories
3. **Sprint Planning Optimizer** - Use historical velocity and team capacity to optimize sprint planning

**Q2-Q3 Focus:**
1. **Knowledge Base Productization** - Transform internal wiki/documentation into client-deliverable knowledge base
2. **Test Automation Suite** - Generate unit and integration tests from code and requirements
3. **Documentation Auto-Generator** - Auto-generate API documentation from code

**Q3-Q4 Focus:**
1. **Project Management Automation** - Predictive analytics for project health and risk
2. **Research Tools** - Competitive analysis and tech stack research automation
3. **White-Label Pattern Library** - Reusable client-facing templates and components

---

## 5. WORKFLOW INTERVIEW PIPELINE

### Interview Process
1. Schedule 45-60 min session with PM/Dev/Designer
2. Use structured interview template (see Resources section)
3. Identify 3-5 pain points per interview
4. Prioritize tool opportunities based on impact and feasibility
5. Document findings in interview tracker

### Interview Tracker

| # | Date | Role | Team | Pain Points Identified | Tool Ideas | Priority |
|---|------|------|------|------------------------|------------|----------|
| 1 | TBD | TBD | TBD | [To be filled after first interview] | [To be filled] | H/M/L |

**Target:** 5 interviews per quarter (20 total in 2026)
**Progress:** 0/5 completed in Q1

---

## 6. RESEARCH TO PORTFOLIO PIPELINE

### Weekly Research Workflow

**Monday (30 min):**
- Read AI newsletters (Anthropic, LangChain, AI Safety)
- Capture AI Leads (tools, techniques, papers)
- Share LinkedIn post (thought leadership / insights)

**Wednesday (2 hours):**
- Hands-on experiment with new AI technique or tool
- Document findings in GitHub or personal notes
- Identify potential CSG applicability

**Friday (30 min AM):**
- Participate in GitHub discussions
- Network with AI community (Twitter, Discord, forums)

**Friday (30 min PM):**
- Update research tracker
- Reflect on week's learnings
- Plan next week's focus

### Monthly Research Activities → CSG Tool Output

| Research Activity | CSG Tool Output | Timeline |
|-------------------|-----------------|----------|
| DeepLearning.AI Agent Course | Multi-agent pattern library for CSG | Q1 2026 |
| Weekly MCP Server Experiments | 3 new MCP integrations | Q1-Q2 2026 |
| Enterprise Governance Deep-Dive | CSG AI Governance Framework v2.0 | Q2 2026 |
| RAG Knowledge Base Study | Internal knowledge base tool | Q2-Q3 2026 |
| Workflow Automation Deep-Dive | PM automation suite | Q3 2026 |

**Time Allocation:** ~15 hours/month research (3-4 hours/week)
**Justification:** Research feeds tool pipeline, keeps CSG competitive, builds expertise

---

## 7. MEASUREMENT & METRICS

### Baseline Metrics (To Establish in Q1)

**Time-on-Task:**
- Current: [X hours] per sprint report (baseline measurement needed)
- Current: [X hours] per test suite creation (baseline measurement needed)
- Current: [X hours] per requirements doc (baseline measurement needed)

**Quality Metrics:**
- Current: [X%] acceptance rate on first submission (baseline measurement needed)
- Current: [X.X/5] stakeholder satisfaction score (baseline measurement needed)
- Current: [X] revision cycles per deliverable (baseline measurement needed)

**Adoption Metrics:**
- Current: [X%] of projects using AI tools (baseline measurement needed)
- Current: [X] tools requested per month (baseline measurement needed)
- Current: [X%] team awareness of portfolio (baseline measurement needed)

### Tracking Methods
1. **Monthly surveys** - 15 min anonymous survey to all team members
2. **Jira time tracking** - Compare time-on-task before/after tool adoption
3. **Tool usage analytics** - Track usage metrics where possible (API calls, script runs)
4. **Quarterly retrospectives** - Gather qualitative feedback from teams

**Q1 Action Item:** Establish baselines for all metrics by end of March 2026

---

## 8. GOVERNANCE & COMPLIANCE

### CSG AI Standards Checklist v1.0

**Data Security:**
- [ ] No client data in public APIs without explicit client approval
- [ ] API keys stored in secure vault (1Password, Azure Key Vault), never in code
- [ ] Data retention policies followed (auto-delete temp files, respect client data policies)
- [ ] Access controls documented (who can use tool, who can modify code)

**Intellectual Property:**
- [ ] Generated code reviewed by human developer before use
- [ ] Client IP ownership clearly defined in SOW
- [ ] Attribution for open-source components included
- [ ] No client proprietary code used in AI training data

**Bias & Fairness:**
- [ ] Testing includes diverse scenarios (not just happy path)
- [ ] Output reviewed for bias indicators (language, assumptions, edge cases)
- [ ] Escalation path for ethical concerns documented
- [ ] Documentation includes known limitations and failure modes

**Human Review:**
- [ ] AI output NEVER goes directly to client unreviewed
- [ ] Subject matter expert validates accuracy and appropriateness
- [ ] Approval workflow enforced (cannot be bypassed)
- [ ] Audit trail maintained (who reviewed, when, what decision)

**Incident Response:**
- [ ] Process documented for reporting AI-related issues
- [ ] Escalation path defined (who to contact, severity levels)
- [ ] Lessons learned captured from each incident
- [ ] Continuous improvement loop (update tools based on incidents)

**See full checklist:** `CSG_AI_Standards_Checklist_v1.docx` (to be created)

---

## 9. DECISION LOG

### Decision: AI Tooling Portfolio Over Ad-Hoc Automation
**Date:** 2025-12-15
**Decision:** Build reusable portfolio of AI tools instead of one-off scripts per project
**Rationale:**
- Compounding value - each tool makes future tools easier
- Knowledge sharing across teams
- Consistent quality standards
- Easier maintenance and updates
- Better governance and compliance
**Alternatives Considered:**
- Team-specific tools (rejected: leads to duplication, inconsistent quality)
- No AI tools (rejected: CSG falls behind competitors)
- Ad-hoc scripts (rejected: no reuse, high maintenance)

### Decision: Free/Open Source Tools First, Paid APIs Later
**Date:** 2026-01-08
**Decision:** CSG Sprint Reporter uses no AI APIs (pure Python + Jira/Fathom APIs)
**Rationale:**
- Eliminates ongoing AI API costs (free to run)
- Faster execution (no external API latency)
- No rate limits or throttling concerns
- Easier to maintain and debug
- Proves value before adding complexity
**Alternatives Considered:**
- Use Claude API for sprint summarization (rejected: unnecessary overhead, adds cost)
- Use GPT-4 for meeting insights (rejected: Fathom already provides summaries)
**When to use paid APIs:** When AI is core to the tool's value prop (e.g., requirements→user stories generation)

### Decision: Markdown for CSG-CONTEXT.md (This File)
**Date:** 2026-01-15
**Decision:** Use Markdown format for permanent CSG knowledge base
**Rationale:**
- Version control friendly (git tracks changes)
- Plain text (accessible in any editor, never gets corrupted)
- Claude Code can read/search efficiently
- Easy to update and maintain
- Can generate Word/PDF for sharing when needed
**Alternatives Considered:**
- Word document (rejected: binary format, merge conflicts, version control issues)
- Confluence/Wiki (rejected: requires network access, harder to version control)

[More decisions to be added as they occur]

---

## 10. WEEKLY RITUALS

### Monday Morning (9-11 AM)
- **Biweekly AI Vertical Scan** (every other week)
  - Review 12 AI verticals systematically
  - Document findings in `AI_Vertical_CheckIn_YYYY-MM-DD.md`
  - Identify CSG-relevant opportunities
- Review week's priorities
- Check interview schedule

### Tuesday-Thursday Morning (8:30-9 AM)
- **Daily AI Research Scan** (30 min)
  - Check newsletters (Anthropic, LangChain, etc.)
  - Scan Twitter/Reddit for AI developments
  - Review RSS feeds in Feedly
  - Flag items for deeper investigation

### Friday Afternoon (2-4 PM)
- **Weekly AI Deep-Dive** (2 hours)
  - Hour 1: Hands-on experimentation with new tool/technique
  - Hour 2: Strategic synthesis, connect to CSG opportunities
  - Document learnings

### Friday End-of-Week (4:30-5 PM)
- Update CSG-CONTEXT.md if needed (add decisions, update metrics, note changes)
- Update tool portfolio catalog (new tools, status changes)
- Capture lessons learned from the week
- Commit changes to git

---

## 11. KEY STAKEHOLDERS

### Internal CSG
- **[Name/Role]** - Portfolio sponsor (executive sponsorship)
- **[Name/Role]** - Tech lead (technical oversight)
- **[Teams]** - Early adopters (pilot teams for new tools)

[To be filled during interview]

### External
- **BargeOps** - Current client, pilot for CSG Sprint Reporter
- **[Other clients]** - Potential case study opportunities

[To be expanded]

---

## 12. RESOURCES & LINKS

### Documentation
- **Portfolio Strategy:** `C:\Users\layden\Downloads\CSG_AI_Tooling_Portfolio_Kickstart_Context_IMPROVED.md`
- **Sprint Reporter:** `C:\Users\layden\scripts\CSG-SPRINT-REPORTER-README.md`
- **Research Plan:** `C:\Users\layden\Downloads\Luke_Layden_AI_Research_Plan_2026.md`
- **Certification Strategy:** `C:\Users\layden\Downloads\Luke_AI_Certification_Strategy_2026.md`
- **AI Vertical Tracking:** `C:\Users\layden\Downloads\AI_Vertical_Tracking_System.md`

### Tools & Systems
- **Jira Board:** Board 38 (BargeOps)
- **Fathom:** Meeting recording and transcription
- **GitHub:** [Luke's repositories]
- **Shared Drive:** `OneDrive - Cornerstone Solutions Group`

### Upcoming Deliverables (Q1 2026)
- `CSG_AI_Portfolio_Presentation.pptx` - Executive presentation (in progress)
- `CSG_AI_Tooling_Portfolio_2026_Plan_FINAL.docx` - Supporting document (in progress)
- `CSG_Tool_Intake_Rubric.docx` - Evaluation form (in progress)
- `CSG_AI_Standards_Checklist_v1.docx` - Governance checklist (in progress)

---

## 13. CHANGE LOG

### 2026-01-15 - Initial Creation
- Created CSG-CONTEXT.md structure
- Populated Section 3 (AI Tooling Portfolio OKRs)
- Populated Section 4 (Tool Portfolio Catalog - Sprint Reporter entry)
- Populated Section 6 (Research to Portfolio Pipeline)
- Populated Section 9 (Decision Log - 3 initial decisions)
- Next: Conduct business model interview to fill Section 1

### [Future dates]
[Document all significant updates to this file]

---

**Next Review:** Daily (end-of-week updates on Fridays)
**Owner:** Luke Layden, Solution Delivery Manager
**Purpose:** Permanent business context that persists across all Claude Code sessions
**Version Control:** Tracked in git, commit after each significant update
